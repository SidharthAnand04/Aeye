# Aeye â€” Real-time Assistive Vision for Blind & Low-Vision Users

Camera-based AI assistant that detects obstacles, reads text, and describes scenesâ€”all in real time with spoken feedback.

> ğŸ† Built for Keywords AI Hackathon 2026

## Demo

<div align="center">
  <a href="https://www.youtube.com/watch?v=FT2MSTotdO0" target="_blank">
    <img src="https://img.youtube.com/vi/FT2MSTotdO0/maxresdefault.jpg" alt="Aeye Demo Video" width="560">
  </a>
</div>

---

## Quick Start

### Prerequisites
- Python 3.10+ with [uv](https://github.com/astral-sh/uv)
- Node.js 18+
- Keywords AI API key

### 1. Backend Setup
```bash
cd backend
uv sync
cp .env.example .env
# Edit .env with your KEYWORDS_AI_API_KEY
uv run uvicorn app.main:app --reload --port 8000
```

### 2. Frontend Setup
```bash
cd frontend
npm install
npm start
```

### 3. Open http://localhost:3000

---

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           FRONTEND (React)                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Camera     â”‚  â”‚  Bounding   â”‚  â”‚  Control    â”‚  â”‚  Trace      â”‚    â”‚
â”‚  â”‚  Stream     â”‚  â”‚  Box        â”‚  â”‚  Panel      â”‚  â”‚  Panel      â”‚    â”‚
â”‚  â”‚  (1-5 FPS)  â”‚  â”‚  Overlay    â”‚  â”‚             â”‚  â”‚  (Judges)   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚                â”‚                â”‚                â”‚            â”‚
â”‚         â”‚  base64 frame  â”‚  detections    â”‚                â”‚  trace     â”‚
â”‚         â–¼                â”‚                â–¼                â”‚            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    useDetection Hook                              â”‚  â”‚
â”‚  â”‚  processFrame() â”‚ readText() â”‚ describeScene()                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                       â”‚                                       â”‚
â”‚         â”‚   Web Speech API      â”‚                                       â”‚
â”‚         â–¼                       â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚  â”‚  useSpeech  â”‚         â”‚  HTTP POST  â”‚                               â”‚
â”‚  â”‚  (TTS)      â”‚         â”‚  /pipeline  â”‚                               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           BACKEND (FastAPI)                              â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                        API Endpoints                                â”‚ â”‚
â”‚  â”‚  POST /pipeline â”‚ POST /detect â”‚ POST /ocr â”‚ POST /describe        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                   â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                      PERCEPTION LAYER                               â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚ â”‚
â”‚  â”‚  â”‚  YOLOv8n     â”‚  â”‚  EasyOCR     â”‚  â”‚  IOU         â”‚              â”‚ â”‚
â”‚  â”‚  â”‚  Detector    â”‚  â”‚  Engine      â”‚  â”‚  Tracker     â”‚              â”‚ â”‚
â”‚  â”‚  â”‚  (~100ms)    â”‚  â”‚  (~350ms)    â”‚  â”‚  (~5ms)      â”‚              â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                   â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                        AGENT LAYER                                  â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚ â”‚
â”‚  â”‚  â”‚  Priority    â”‚  â”‚  Novelty &   â”‚  â”‚  Speech      â”‚              â”‚ â”‚
â”‚  â”‚  â”‚  Scoring     â”‚  â”‚  Cooldown    â”‚  â”‚  Generation  â”‚              â”‚ â”‚
â”‚  â”‚  â”‚              â”‚  â”‚  Gates       â”‚  â”‚              â”‚              â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                   â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                      KEYWORDS AI CLIENT                             â”‚ â”‚
â”‚  â”‚  Claude Haiku via Keywords AI API                                   â”‚ â”‚
â”‚  â”‚  - Scene descriptions                                               â”‚ â”‚
â”‚  â”‚  - Tool calling (speak_alert, describe_scene)                       â”‚ â”‚
â”‚  â”‚  - Trace logging                                                    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## MVP Features

### 1. Real-time object detection
- Detect: person, car, bike, dog, chair, doors, stairs
- Shows bounding boxes in UI (for judges)
- Speaks key detections for accessibility
- Updates continuously (1â€“5 FPS)

### 2. Smart audio notifications
- **Priority rules**: moving obstacles near center > static clutter > background
- **Cooldowns**: don't repeat "person" every frame
- **Novelty triggers**: only speak when something changes (new object / gets close / enters path)
- Result: fewer false alerts, more useful warnings

### 3. On-demand "Describe scene"
- User presses button or voice command
- Returns short summary: *"Two people ahead. Door on the right. Chair in the middle."*
- Speaks result immediately

### 4. Text reading mode (OCR)
- User taps "Read text" â†’ capture frame â†’ OCR â†’ speak
- Handles labels, signs, menus
- Quick and demoable

### 5. Voice booster
- Press-and-hold to talk
- Speech-to-text â†’ re-speak with louder TTS
- Quick phrase buttons: *"Excuse me"*, *"Can you help me findâ€¦"*, *"I can't see well."*

## Architecture

[ Camera / Glasses Feed ]
â†“
[ Perception Layer ] (object detection, OCR, STT)
â†“
[ Agent / Reasoning Layer ] (prioritization, novelty triggers, cooldowns)
â†“
[ Output Layer ] (audio feedback + judge UI)

## Data interfaces

Perception â†’ Agent (detections)

Example (normalized bbox = [x1, y1, x2, y2]):

```yaml
t: 1730.24
detections:
	- label: person
		conf: 0.91
		bbox: [0.42, 0.18, 0.62, 0.92]
	- label: chair
		conf: 0.77
		bbox: [0.10, 0.55, 0.28, 0.90]
```

Agent â†’ Output (action)

```yaml
t: 1730.40
action: SPEAK
text: "Person ahead, slightly right."
trace:
	top_objects:
		- id: 3
			label: person
			score: 2.31
			reasons: [in_path, approaching]
	gates:
		novelty: true
		cooldown_ok: true
		global_rate_ok: true
```

## Agent design (summary)

- World state: per-object memory (id, label, smoothed bbox, last_seen, last_spoken, motion/proximity proxies)
- Tracking: simple IOU matching is sufficient for MVP
- Prioritization score: class weight, in-path weight, proximity, approach, motion
- Novelty triggers: speak when new/entered path/near/approaching
- Cooldowns & rate limits: per-object ~3â€“6s, per-class optional, global cap ~1.2â€“2.0s; override on risk

## Output templates

- Alerts: â€œPerson aheadâ€, â€œObstacle in pathâ€, â€œBike approaching leftâ€
- Escalation: â€œVery closeâ€
- Find mode guidance: â€œLeftâ€, â€œRightâ€, â€œForwardâ€

## Modes & UI

- Live Assist â€” continuous prioritized alerts
- Read Text â€” capture & read OCR text
- Describe â€” capture & summarize scene
- Optional: Find mode (target search)

## Suggested backend endpoints

- `POST /detect` â€” input: image frame â†’ output: detections
- `POST /ocr` â€” input: image frame â†’ output: text
- `POST /describe` â€” input: image frame â†’ output: short summary
- `POST /agent/step` â€” input: t, detections, mode, settings â†’ output: action, text, trace

## Build plan (hackathon timeline)

Phase 1 â€” End-to-end loop

- Camera stream @ 1â€“5 FPS
- Draw boxes in UI
- Implement agent scoring & speak gating
- Speech log

Phase 2 â€” On-demand tools

- Read Text (OCR)
- Describe Scene

Phase 3 â€” Polish for judges

- Settings (verbosity, rate, mute)
- Trace panel with gates & top objects
- Record â‰¤2 minute demo video

## Demo script (â‰ˆ2 minutes)

1. Live Assist: show clutter; agent speaks only key items
2. Approach scenario: person enters view â†’ one announcement; move closer â†’ escalate
3. Read Text: point at sign, tap Read, it speaks
4. Describe: tap Describe, it summarizes
5. Optional: Voice Booster demo

## Safety & privacy

- Default: do not store raw frames
- Log only structured events (detections, spoken text) for replay
- Provide visible indicator when camera processing is active

## Tech stack (suggested)

- Frontend: web app (camera + TTS)
- Backend: FastAPI / Flask
- Storage: Supabase (settings + logs)
- Orchestration: Keywords AI (tool calls + trace)

## Success metrics (for Devpost)

- Speech rate: â‰¤ 1 message / ~1.5s
- Alert usefulness: announces only when novel/risky
- Navigation proxy: fewer spam repeats, accurate directional cues
- Demo reliability: works in noisy room; optional visual fallback

